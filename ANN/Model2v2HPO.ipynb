{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, still in the process of experimenting with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pds\n",
    "from tensorflow import keras\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Previous best:\n",
    "    {'Dense': 2,\n",
    "     'Dense_1': 4,\n",
    "     'Dense_2': 0,\n",
    "     'activation': 1,\n",
    "     'activation_1': 0,\n",
    "     'batch_size': 1,\n",
    "     'optimizer': 1}\n",
    "    {'Dense': 2,\n",
    "     'Dense_1': 2,\n",
    "     'Dense_2': 1,\n",
    "     'activation': 2,\n",
    "     'activation_1': 0,\n",
    "     'activation_2': 1,\n",
    "     'batch_size': 0,\n",
    "     'optimizer': 0}\n",
    "     {'Dense': 2,\n",
    "     'Dense_1': 1,\n",
    "     'Dense_2': 1,\n",
    "     'activation': 1,\n",
    "     'activation_1': 2,\n",
    "     'activation_2': 0,\n",
    "     'activation_3': 1,\n",
    "     'batch_size': 0}\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense({{choice([3,19,38])}}, activation={{choice([None, 'relu', 'tanh'])}}, input_shape=(19,)))\n",
    "    model.add(Dense({{choice([1,19,38])}}, activation={{choice([None, 'relu', 'tanh'])}}))\n",
    "    model.add(Dense({{choice([1,19,38])}}, activation={{choice([None, 'relu', 'tanh'])}}))\n",
    "    model.add(Dense(1, activation={{choice([None, 'relu'])}}))\n",
    "\n",
    "    model.compile(loss='mae', \n",
    "                  optimizer='Adam',\n",
    "                  metrics=['mae']\n",
    "                 )\n",
    "    \n",
    "    #result = model.fit(x_train,\n",
    "    #                  y_train,\n",
    "    ##                  epochs = 5,\n",
    "    #                  batch_size=10,\n",
    "    #                  validation_data=[x_test, y_test])\n",
    "    result = model.fit(x_train, y_train,\n",
    "                   batch_size={{choice([64, 128])}},\n",
    "                   epochs=3,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.1)\n",
    "    \n",
    "    loss_metric = np.amax(result.history['mean_absolute_error']) \n",
    "    print('Current epoch:', result.history['mean_absolute_error'])\n",
    "    return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    df = pds.read_pickle('ANN_dataset.pkl')\n",
    "    \n",
    "    labels = df['time_left']\n",
    "    #dataset = dataset.drop(columns=['time_left', 'segment_time']) \n",
    "    \n",
    "    # Make segments categorical\n",
    "    dataset = pds.get_dummies(df['seg'])\n",
    "\n",
    "    # Combine segments, timestamps and time from journey start\n",
    "\n",
    "    # Cyclical timestamps \n",
    "    dataset['hr_sin'] = np.sin(df.timestamp.dt.hour*(2.*np.pi/24))\n",
    "    dataset['hr_cos'] = np.cos(df.timestamp.dt.hour*(2.*np.pi/24))\n",
    "\n",
    "    # Convert to radians befor trigonometric functions\n",
    "    dataset['dir_sin'] = np.sin(df.direction*(np.pi/180))\n",
    "    dataset['dir_cos'] = np.cos(df.direction*(np.pi/180))\n",
    "\n",
    "    dataset['speed'] = (df['speed']-df['speed'].min())/(df['speed'].max()-df['speed'].min())\n",
    "    dataset['tsjs'] = (df['tsjs']-df['tsjs'].min())/(df['tsjs'].max()-df['tsjs'].min())\n",
    "\n",
    "    dataset['lat'] = (df['lat']-df['lat'].min())/(df['lat'].max()-df['lat'].min())\n",
    "    dataset['lon'] = (df['lon']-df['lon'].min())/(df['lon'].max()-df['lon'].min())\n",
    "    \n",
    "    # Include journey number to select entire journeys\n",
    "    dataset['journey'] = df['journey']\n",
    "    \n",
    "    \n",
    "    divider = 0.2\n",
    "    num_journeys = dataset.journey.unique()[-1]\n",
    "    num_test_segments = np.int_(np.round(num_journeys*divider))\n",
    "    msk = np.random.randint(1, num_journeys, num_test_segments)\n",
    "    mask = dataset['journey'].isin(msk)\n",
    "\n",
    "    train_input = dataset[~mask]\n",
    "    test_input = dataset[mask]\n",
    "\n",
    "    train_labels = labels[~mask]\n",
    "    test_labels = labels[mask]\n",
    "\n",
    "    train_data = train_input.drop(columns=['journey'])\n",
    "    test_data = test_input.drop(columns=['journey'])\n",
    "\n",
    "    x_train = train_input.drop(columns=['journey'])\n",
    "    x_test = test_data\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pds\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import Adadelta, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [3,19,38]),\n",
      "        'activation': hp.choice('activation', [None, 'relu', 'tanh']),\n",
      "        'Dense_1': hp.choice('Dense_1', [1,19,38]),\n",
      "        'activation_1': hp.choice('activation_1', [None, 'relu', 'tanh']),\n",
      "        'Dense_2': hp.choice('Dense_2', [1,19,38]),\n",
      "        'activation_2': hp.choice('activation_2', [None, 'relu', 'tanh']),\n",
      "        'activation_3': hp.choice('activation_3', [None, 'relu']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: df = pds.read_pickle('ANN_dataset.pkl')\n",
      "   3: \n",
      "   4: labels = df['time_left']\n",
      "   5: #dataset = dataset.drop(columns=['time_left', 'segment_time']) \n",
      "   6: \n",
      "   7: # Make segments categorical\n",
      "   8: dataset = pds.get_dummies(df['seg'])\n",
      "   9: \n",
      "  10: # Combine segments, timestamps and time from journey start\n",
      "  11: \n",
      "  12: # Cyclical timestamps \n",
      "  13: dataset['hr_sin'] = np.sin(df.timestamp.dt.hour*(2.*np.pi/24))\n",
      "  14: dataset['hr_cos'] = np.cos(df.timestamp.dt.hour*(2.*np.pi/24))\n",
      "  15: \n",
      "  16: # Convert to radians befor trigonometric functions\n",
      "  17: dataset['dir_sin'] = np.sin(df.direction*(np.pi/180))\n",
      "  18: dataset['dir_cos'] = np.cos(df.direction*(np.pi/180))\n",
      "  19: \n",
      "  20: dataset['speed'] = (df['speed']-df['speed'].min())/(df['speed'].max()-df['speed'].min())\n",
      "  21: dataset['tsjs'] = (df['tsjs']-df['tsjs'].min())/(df['tsjs'].max()-df['tsjs'].min())\n",
      "  22: \n",
      "  23: dataset['lat'] = (df['lat']-df['lat'].min())/(df['lat'].max()-df['lat'].min())\n",
      "  24: dataset['lon'] = (df['lon']-df['lon'].min())/(df['lon'].max()-df['lon'].min())\n",
      "  25: \n",
      "  26: # Include journey number to select entire journeys\n",
      "  27: dataset['journey'] = df['journey']\n",
      "  28: \n",
      "  29: \n",
      "  30: divider = 0.2\n",
      "  31: num_journeys = dataset.journey.unique()[-1]\n",
      "  32: num_test_segments = np.int_(np.round(num_journeys*divider))\n",
      "  33: msk = np.random.randint(1, num_journeys, num_test_segments)\n",
      "  34: mask = dataset['journey'].isin(msk)\n",
      "  35: \n",
      "  36: train_input = dataset[~mask]\n",
      "  37: test_input = dataset[mask]\n",
      "  38: \n",
      "  39: train_labels = labels[~mask]\n",
      "  40: test_labels = labels[mask]\n",
      "  41: \n",
      "  42: train_data = train_input.drop(columns=['journey'])\n",
      "  43: test_data = test_input.drop(columns=['journey'])\n",
      "  44: \n",
      "  45: x_train = train_input.drop(columns=['journey'])\n",
      "  46: x_test = test_data\n",
      "  47: y_train = train_labels\n",
      "  48: y_test = test_labels\n",
      "  49: \n",
      "  50: \n",
      "  51: \n",
      "  52: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \"\"\"\n",
      "   4:     Previous best:\n",
      "   5:     {'Dense': 2,\n",
      "   6:      'Dense_1': 4,\n",
      "   7:      'Dense_2': 0,\n",
      "   8:      'activation': 1,\n",
      "   9:      'activation_1': 0,\n",
      "  10:      'batch_size': 1,\n",
      "  11:      'optimizer': 1}\n",
      "  12:     {'Dense': 2,\n",
      "  13:      'Dense_1': 2,\n",
      "  14:      'Dense_2': 1,\n",
      "  15:      'activation': 2,\n",
      "  16:      'activation_1': 0,\n",
      "  17:      'activation_2': 1,\n",
      "  18:      'batch_size': 0,\n",
      "  19:      'optimizer': 0}\n",
      "  20:     \"\"\"\n",
      "  21:     model = Sequential()\n",
      "  22:     \n",
      "  23:     model.add(Dense(space['Dense'], activation=space['activation'], input_shape=(19,)))\n",
      "  24:     model.add(Dense(space['Dense_1'], activation=space['activation_1']))\n",
      "  25:     model.add(Dense(space['Dense_2'], activation=space['activation_2']))\n",
      "  26:     model.add(Dense(1, activation=space['activation_3']))\n",
      "  27: \n",
      "  28:     model.compile(loss='mae', \n",
      "  29:                   optimizer='Adam',\n",
      "  30:                   metrics=['mae']\n",
      "  31:                  )\n",
      "  32:     \n",
      "  33:     #result = model.fit(x_train,\n",
      "  34:     #                  y_train,\n",
      "  35:     ##                  epochs = 5,\n",
      "  36:     #                  batch_size=10,\n",
      "  37:     #                  validation_data=[x_test, y_test])\n",
      "  38:     result = model.fit(x_train, y_train,\n",
      "  39:                    batch_size=space['batch_size'],\n",
      "  40:                    epochs=3,\n",
      "  41:                    verbose=1,\n",
      "  42:                    validation_split=0.1)\n",
      "  43:     \n",
      "  44:     loss_metric = np.amax(result.history['mean_absolute_error']) \n",
      "  45:     print('Current epoch:', result.history['mean_absolute_error'])\n",
      "  46:     return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}\n",
      "  47: \n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 34s 14us/step - loss: 12.3877 - mean_absolute_error: 12.3877 - val_loss: 12.1577 - val_mean_absolute_error: 12.1577\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 32s 13us/step - loss: 11.5052 - mean_absolute_error: 11.5052 - val_loss: 11.8628 - val_mean_absolute_error: 11.8628\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 32s 13us/step - loss: 11.3562 - mean_absolute_error: 11.3562 - val_loss: 11.7152 - val_mean_absolute_error: 11.7152\n",
      "Current epoch: [12.387687835349505, 11.505183302327586, 11.356246032983162]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 35s 14us/step - loss: 13.1052 - mean_absolute_error: 13.1052 - val_loss: 12.2903 - val_mean_absolute_error: 12.2903\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 33s 13us/step - loss: 11.7507 - mean_absolute_error: 11.7507 - val_loss: 11.9944 - val_mean_absolute_error: 11.9944\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 33s 14us/step - loss: 11.5799 - mean_absolute_error: 11.5799 - val_loss: 11.8766 - val_mean_absolute_error: 11.8766\n",
      "Current epoch: [13.105220825823242, 11.75066154919576, 11.579918000127542]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 19s 8us/step - loss: 15.6222 - mean_absolute_error: 15.6222 - val_loss: 12.2767 - val_mean_absolute_error: 12.2767\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 18s 8us/step - loss: 11.7291 - mean_absolute_error: 11.7291 - val_loss: 12.0258 - val_mean_absolute_error: 12.0258\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 18s 8us/step - loss: 11.6427 - mean_absolute_error: 11.6427 - val_loss: 12.0765 - val_mean_absolute_error: 12.0765\n",
      "Current epoch: [15.622166276128697, 11.729090160914422, 11.642670530099952]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 19s 8us/step - loss: 13.7217 - mean_absolute_error: 13.7217 - val_loss: 12.5107 - val_mean_absolute_error: 12.5107\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 19s 8us/step - loss: 11.9795 - mean_absolute_error: 11.9795 - val_loss: 12.3380 - val_mean_absolute_error: 12.3380\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 19s 8us/step - loss: 11.8985 - mean_absolute_error: 11.8985 - val_loss: 12.3165 - val_mean_absolute_error: 12.3165\n",
      "Current epoch: [13.721686327504951, 11.979528782753404, 11.89847032760215]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 20s 8us/step - loss: 17.1455 - mean_absolute_error: 17.1455 - val_loss: 13.6636 - val_mean_absolute_error: 13.6636\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 20s 8us/step - loss: 12.9661 - mean_absolute_error: 12.9661 - val_loss: 13.2880 - val_mean_absolute_error: 13.2880\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 20s 8us/step - loss: 12.6660 - mean_absolute_error: 12.6660 - val_loss: 13.0524 - val_mean_absolute_error: 13.0524\n",
      "Current epoch: [17.145471474354665, 12.96607936621079, 12.666047238170826]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444208/2444208 [==============================] - 35s 14us/step - loss: 40.0539 - mean_absolute_error: 40.0539 - val_loss: 27.3878 - val_mean_absolute_error: 27.3878\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 35s 14us/step - loss: 19.7822 - mean_absolute_error: 19.7822 - val_loss: 15.2641 - val_mean_absolute_error: 15.2641\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 35s 14us/step - loss: 14.0500 - mean_absolute_error: 14.0500 - val_loss: 13.7494 - val_mean_absolute_error: 13.7494\n",
      "Current epoch: [40.05386385135405, 19.782226186643832, 14.049987618650048]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 20s 8us/step - loss: 14.0223 - mean_absolute_error: 14.0223 - val_loss: 12.7210 - val_mean_absolute_error: 12.7210\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 20s 8us/step - loss: 12.0135 - mean_absolute_error: 12.0135 - val_loss: 12.4850 - val_mean_absolute_error: 12.4850\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 20s 8us/step - loss: 11.7433 - mean_absolute_error: 11.7433 - val_loss: 12.1540 - val_mean_absolute_error: 12.1540\n",
      "Current epoch: [14.022310996915085, 12.013465256633326, 11.743315611208187]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 37s 15us/step - loss: 57.7015 - mean_absolute_error: 57.7015 - val_loss: 57.8580 - val_mean_absolute_error: 57.8580\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 36s 15us/step - loss: 57.7015 - mean_absolute_error: 57.7015 - val_loss: 57.8580 - val_mean_absolute_error: 57.8580\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 36s 15us/step - loss: 57.7015 - mean_absolute_error: 57.7015 - val_loss: 57.8580 - val_mean_absolute_error: 57.8580\n",
      "Current epoch: [57.70154193114975, 57.70154193097495, 57.70154193124963]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 37s 15us/step - loss: 15.1151 - mean_absolute_error: 15.1151 - val_loss: 13.0125 - val_mean_absolute_error: 13.0125\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 37s 15us/step - loss: 12.2373 - mean_absolute_error: 12.2373 - val_loss: 12.6135 - val_mean_absolute_error: 12.6135\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 37s 15us/step - loss: 12.0481 - mean_absolute_error: 12.0481 - val_loss: 12.4422 - val_mean_absolute_error: 12.4422\n",
      "Current epoch: [15.115087272501857, 12.237333479296128, 12.048072579948583]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 22s 9us/step - loss: 49.8849 - mean_absolute_error: 49.8849 - val_loss: 43.6865 - val_mean_absolute_error: 43.6865\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 22s 9us/step - loss: 39.8944 - mean_absolute_error: 39.8944 - val_loss: 37.7394 - val_mean_absolute_error: 37.7394\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 22s 9us/step - loss: 37.0840 - mean_absolute_error: 37.0840 - val_loss: 37.1793 - val_mean_absolute_error: 37.1793\n",
      "Current epoch: [49.8849028998638, 39.89442033201413, 37.083965645419006]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 17.8474 - mean_absolute_error: 17.8474 - val_loss: 11.8735 - val_mean_absolute_error: 11.8735\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 24s 10us/step - loss: 11.4257 - mean_absolute_error: 11.4257 - val_loss: 11.7550 - val_mean_absolute_error: 11.7550\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.2760 - mean_absolute_error: 11.2760 - val_loss: 11.6041 - val_mean_absolute_error: 11.6041\n",
      "Current epoch: [17.847444938650227, 11.425728099008408, 11.276028988572257]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 12.6911 - mean_absolute_error: 12.6911 - val_loss: 12.1316 - val_mean_absolute_error: 12.1316\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.5953 - mean_absolute_error: 11.5953 - val_loss: 11.9483 - val_mean_absolute_error: 11.9483\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 22s 9us/step - loss: 11.4742 - mean_absolute_error: 11.4742 - val_loss: 11.8916 - val_mean_absolute_error: 11.8916\n",
      "Current epoch: [12.691060412675556, 11.59526662528193, 11.474225608865039]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 18.6785 - mean_absolute_error: 18.6785 - val_loss: 12.0983 - val_mean_absolute_error: 12.0983\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.5065 - mean_absolute_error: 11.5065 - val_loss: 11.9058 - val_mean_absolute_error: 11.9058\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.3637 - mean_absolute_error: 11.3637 - val_loss: 11.8647 - val_mean_absolute_error: 11.8647\n",
      "Current epoch: [18.67847291964228, 11.506542703302127, 11.363682364557217]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 41s 17us/step - loss: 14.8106 - mean_absolute_error: 14.8106 - val_loss: 13.6766 - val_mean_absolute_error: 13.6766\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 39s 16us/step - loss: 13.1062 - mean_absolute_error: 13.1062 - val_loss: 13.5359 - val_mean_absolute_error: 13.5359\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 40s 16us/step - loss: 13.0083 - mean_absolute_error: 13.0083 - val_loss: 13.4387 - val_mean_absolute_error: 13.4387\n",
      "Current epoch: [14.81063660183602, 13.106166921081101, 13.008329008550191]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 25s 10us/step - loss: 12.9157 - mean_absolute_error: 12.9157 - val_loss: 12.3424 - val_mean_absolute_error: 12.3424\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 27s 11us/step - loss: 11.6969 - mean_absolute_error: 11.6969 - val_loss: 12.0828 - val_mean_absolute_error: 12.0828\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 24s 10us/step - loss: 11.5310 - mean_absolute_error: 11.5310 - val_loss: 11.9901 - val_mean_absolute_error: 11.9901\n",
      "Current epoch: [12.91566987604914, 11.696911426258593, 11.53095006610318]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 26s 10us/step - loss: 19.2169 - mean_absolute_error: 19.2169 - val_loss: 18.6789 - val_mean_absolute_error: 18.6789\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 23s 10us/step - loss: 18.2233 - mean_absolute_error: 18.2233 - val_loss: 18.6633 - val_mean_absolute_error: 18.6633\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 24s 10us/step - loss: 18.2176 - mean_absolute_error: 18.2176 - val_loss: 18.6461 - val_mean_absolute_error: 18.6461\n",
      "Current epoch: [19.216874138832274, 18.223276415113002, 18.217618560111795]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 24s 10us/step - loss: 18.4900 - mean_absolute_error: 18.4900 - val_loss: 15.0691 - val_mean_absolute_error: 15.0691\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 22s 9us/step - loss: 14.0877 - mean_absolute_error: 14.0877 - val_loss: 14.0543 - val_mean_absolute_error: 14.0543\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 13.4638 - mean_absolute_error: 13.4638 - val_loss: 13.8061 - val_mean_absolute_error: 13.8061\n",
      "Current epoch: [18.489983122711322, 14.087738381420495, 13.463765054669809]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 25s 10us/step - loss: 14.0649 - mean_absolute_error: 14.0649 - val_loss: 12.7973 - val_mean_absolute_error: 12.7973\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 23s 10us/step - loss: 12.0952 - mean_absolute_error: 12.0952 - val_loss: 12.4878 - val_mean_absolute_error: 12.4878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.8679 - mean_absolute_error: 11.8679 - val_loss: 12.3197 - val_mean_absolute_error: 12.3197\n",
      "Current epoch: [14.064938982000811, 12.095236708270846, 11.86793007407437]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 44s 18us/step - loss: 12.6287 - mean_absolute_error: 12.6287 - val_loss: 12.1053 - val_mean_absolute_error: 12.1053\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 44s 18us/step - loss: 11.6003 - mean_absolute_error: 11.6003 - val_loss: 11.9101 - val_mean_absolute_error: 11.9101\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 42s 17us/step - loss: 11.4946 - mean_absolute_error: 11.4946 - val_loss: 11.8452 - val_mean_absolute_error: 11.8452\n",
      "Current epoch: [12.628712596885695, 11.60030536630136, 11.494641440150511]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 26s 10us/step - loss: 13.1324 - mean_absolute_error: 13.1324 - val_loss: 12.2518 - val_mean_absolute_error: 12.2518\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.7847 - mean_absolute_error: 11.7847 - val_loss: 12.1536 - val_mean_absolute_error: 12.1536\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 23s 9us/step - loss: 11.6991 - mean_absolute_error: 11.6991 - val_loss: 12.0724 - val_mean_absolute_error: 12.0724\n",
      "Current epoch: [13.132397241493084, 11.784732180748017, 11.699058479070157]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 44s 18us/step - loss: 12.4890 - mean_absolute_error: 12.4890 - val_loss: 12.1154 - val_mean_absolute_error: 12.1154\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 44s 18us/step - loss: 11.6038 - mean_absolute_error: 11.6038 - val_loss: 12.1051 - val_mean_absolute_error: 12.1051\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 43s 18us/step - loss: 11.4731 - mean_absolute_error: 11.4731 - val_loss: 11.8575 - val_mean_absolute_error: 11.8575\n",
      "Current epoch: [12.489035906430571, 11.603758129758566, 11.47306301149556]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 45s 19us/step - loss: 12.6608 - mean_absolute_error: 12.6608 - val_loss: 12.1855 - val_mean_absolute_error: 12.1855\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 43s 18us/step - loss: 11.7151 - mean_absolute_error: 11.7151 - val_loss: 12.1143 - val_mean_absolute_error: 12.1143\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 45s 19us/step - loss: 11.5547 - mean_absolute_error: 11.5547 - val_loss: 12.0390 - val_mean_absolute_error: 12.0390\n",
      "Current epoch: [12.660842125079453, 11.715066723035608, 11.554660969078052]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 47s 19us/step - loss: 12.5653 - mean_absolute_error: 12.5653 - val_loss: 12.2615 - val_mean_absolute_error: 12.2615\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 47s 19us/step - loss: 11.6411 - mean_absolute_error: 11.6411 - val_loss: 12.0081 - val_mean_absolute_error: 12.0081\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 47s 19us/step - loss: 11.5270 - mean_absolute_error: 11.5270 - val_loss: 11.8703 - val_mean_absolute_error: 11.8703\n",
      "Current epoch: [12.565308236495534, 11.64110705191127, 11.52702504247898]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 49s 20us/step - loss: 12.6188 - mean_absolute_error: 12.6188 - val_loss: 12.0975 - val_mean_absolute_error: 12.0975\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 48s 20us/step - loss: 11.6084 - mean_absolute_error: 11.6084 - val_loss: 12.1824 - val_mean_absolute_error: 12.1824\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 49s 20us/step - loss: 11.4881 - mean_absolute_error: 11.4881 - val_loss: 11.8748 - val_mean_absolute_error: 11.8748\n",
      "Current epoch: [12.61876959072275, 11.608390091034627, 11.48810724048651]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 51s 21us/step - loss: 12.6194 - mean_absolute_error: 12.6194 - val_loss: 12.0770 - val_mean_absolute_error: 12.0770\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 48s 20us/step - loss: 11.5673 - mean_absolute_error: 11.5673 - val_loss: 11.9064 - val_mean_absolute_error: 11.9064\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 47s 19us/step - loss: 11.4518 - mean_absolute_error: 11.4518 - val_loss: 11.8596 - val_mean_absolute_error: 11.8596\n",
      "Current epoch: [12.619399092108972, 11.56729373131366, 11.451750613816186]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 49s 20us/step - loss: 12.6561 - mean_absolute_error: 12.6561 - val_loss: 12.2235 - val_mean_absolute_error: 12.2235\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 48s 19us/step - loss: 11.6540 - mean_absolute_error: 11.6540 - val_loss: 11.9762 - val_mean_absolute_error: 11.9762\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 49s 20us/step - loss: 11.5051 - mean_absolute_error: 11.5051 - val_loss: 11.8462 - val_mean_absolute_error: 11.8462\n",
      "Current epoch: [12.656071175175047, 11.654034621061781, 11.505136950052558]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 51s 21us/step - loss: 12.6386 - mean_absolute_error: 12.6386 - val_loss: 12.3986 - val_mean_absolute_error: 12.3986\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 50s 20us/step - loss: 11.7339 - mean_absolute_error: 11.7339 - val_loss: 12.1868 - val_mean_absolute_error: 12.1868\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 52s 21us/step - loss: 11.5945 - mean_absolute_error: 11.5945 - val_loss: 12.1560 - val_mean_absolute_error: 12.1560\n",
      "Current epoch: [12.638577747982364, 11.73388502193476, 11.594450076369599]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 52s 21us/step - loss: 12.7482 - mean_absolute_error: 12.7482 - val_loss: 12.2930 - val_mean_absolute_error: 12.2930\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 55s 22us/step - loss: 11.7577 - mean_absolute_error: 11.7577 - val_loss: 12.2857 - val_mean_absolute_error: 12.2857\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 63s 26us/step - loss: 11.6463 - mean_absolute_error: 11.6463 - val_loss: 12.0262 - val_mean_absolute_error: 12.0262\n",
      "Current epoch: [12.748173062431457, 11.757681143038578, 11.646251258267766]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 56s 23us/step - loss: 12.4783 - mean_absolute_error: 12.4783 - val_loss: 12.0538 - val_mean_absolute_error: 12.0538\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 53s 22us/step - loss: 11.5600 - mean_absolute_error: 11.5600 - val_loss: 11.8193 - val_mean_absolute_error: 11.8193\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 53s 22us/step - loss: 11.4203 - mean_absolute_error: 11.4203 - val_loss: 11.7770 - val_mean_absolute_error: 11.7770\n",
      "Current epoch: [12.478309918586772, 11.560049875829657, 11.42031384493281]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 74s 30us/step - loss: 12.4259 - mean_absolute_error: 12.4259 - val_loss: 12.0781 - val_mean_absolute_error: 12.0781\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 70s 29us/step - loss: 11.5703 - mean_absolute_error: 11.5703 - val_loss: 11.9482 - val_mean_absolute_error: 11.9482\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 69s 28us/step - loss: 11.4704 - mean_absolute_error: 11.4704 - val_loss: 11.9217 - val_mean_absolute_error: 11.9217\n",
      "Current epoch: [12.425904845381087, 11.57027648072935, 11.470397616912603]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444208/2444208 [==============================] - 65s 27us/step - loss: 44.9257 - mean_absolute_error: 44.9257 - val_loss: 37.8188 - val_mean_absolute_error: 37.8188\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 62s 25us/step - loss: 37.0512 - mean_absolute_error: 37.0512 - val_loss: 37.1792 - val_mean_absolute_error: 37.1792\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 61s 25us/step - loss: 36.9789 - mean_absolute_error: 36.9789 - val_loss: 37.1793 - val_mean_absolute_error: 37.1793\n",
      "Current epoch: [44.92574022346942, 37.05122048552222, 36.97887174137199]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 60s 25us/step - loss: 12.5892 - mean_absolute_error: 12.5892 - val_loss: 12.0994 - val_mean_absolute_error: 12.0994\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 62s 25us/step - loss: 11.6068 - mean_absolute_error: 11.6068 - val_loss: 11.9545 - val_mean_absolute_error: 11.9545\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 55s 23us/step - loss: 11.4259 - mean_absolute_error: 11.4259 - val_loss: 11.8285 - val_mean_absolute_error: 11.8285\n",
      "Current epoch: [12.589245559662567, 11.606783769400444, 11.425900679468125]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 57s 24us/step - loss: 12.4724 - mean_absolute_error: 12.4724 - val_loss: 12.0251 - val_mean_absolute_error: 12.0251\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 55s 23us/step - loss: 11.5923 - mean_absolute_error: 11.5923 - val_loss: 11.9125 - val_mean_absolute_error: 11.9125\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 56s 23us/step - loss: 11.4370 - mean_absolute_error: 11.4370 - val_loss: 11.7402 - val_mean_absolute_error: 11.7402\n",
      "Current epoch: [12.472398021323652, 11.592278429525818, 11.43697190436586]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 57s 23us/step - loss: 13.9226 - mean_absolute_error: 13.9226 - val_loss: 12.9144 - val_mean_absolute_error: 12.9144\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 66s 27us/step - loss: 12.1865 - mean_absolute_error: 12.1865 - val_loss: 12.4636 - val_mean_absolute_error: 12.4636\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 59s 24us/step - loss: 11.9447 - mean_absolute_error: 11.9447 - val_loss: 12.2605 - val_mean_absolute_error: 12.2605\n",
      "Current epoch: [13.922580400035176, 12.186511205830774, 11.944672332934925]\n",
      "Train on 2444208 samples, validate on 271579 samples\n",
      "Epoch 1/3\n",
      "2444208/2444208 [==============================] - 56s 23us/step - loss: 57.7015 - mean_absolute_error: 57.7015 - val_loss: 57.8580 - val_mean_absolute_error: 57.8580\n",
      "Epoch 2/3\n",
      "2444208/2444208 [==============================] - 55s 23us/step - loss: 57.7015 - mean_absolute_error: 57.7015 - val_loss: 57.8580 - val_mean_absolute_error: 57.8580\n",
      "Epoch 3/3\n",
      "2444208/2444208 [==============================] - 55s 23us/step - loss: 57.7015 - mean_absolute_error: 57.7015 - val_loss: 57.8580 - val_mean_absolute_error: 57.8580\n",
      "Current epoch: [57.701541930725234, 57.701541931099804, 57.70154193114975]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=35,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name=\"Model2v2HPO\"\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': 2,\n",
       " 'Dense_1': 1,\n",
       " 'Dense_2': 1,\n",
       " 'activation': 1,\n",
       " 'activation_1': 2,\n",
       " 'activation_2': 0,\n",
       " 'activation_3': 1,\n",
       " 'batch_size': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
