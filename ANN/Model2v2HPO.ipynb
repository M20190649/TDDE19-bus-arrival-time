{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, still in the process of experimenting with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pds\n",
    "from tensorflow import keras\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Previous best:\n",
    "    {'Dense': 1,\n",
    "     'Dense_1': 1,\n",
    "     'activation': 2,\n",
    "     'activation_1': 0,\n",
    "     'batch_size': 1,\n",
    "     'optimizer': 2}\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense({{choice([3,19,38])}}, input_shape=(19,)))\n",
    "    model.add(Dense({{choice([1,3,8,19,38])}}, activation={{choice([None, 'relu', 'sigmoid', 'tanh'])}}))\n",
    "    model.add(Dense({{choice([1,3,8,19,38])}}, activation={{choice([None, 'relu', 'sigmoid', 'tanh'])}}))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mae', \n",
    "                  optimizer={{choice(['Adadelta', 'Adam', 'sgd'])}},\n",
    "                  metrics=['mae', 'mape']\n",
    "                 )\n",
    "    \n",
    "    #result = model.fit(x_train,\n",
    "    #                  y_train,\n",
    "    ##                  epochs = 5,\n",
    "    #                  batch_size=10,\n",
    "    #                  validation_data=[x_test, y_test])\n",
    "    result = model.fit(x_train, y_train,\n",
    "                   batch_size={{choice([64, 128])}},\n",
    "                   epochs=3,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.1)\n",
    "    \n",
    "    loss_metric = np.amax(result.history['mean_absolute_error']) \n",
    "    print('Current epoch:', result.history['mean_absolute_error'], result.history['mean_absolute_percentage_error'])\n",
    "    return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    data = pds.read_pickle('dataset_model2v2_w_label.pkl')\n",
    "    dataset = data#.iloc[0:10000]\n",
    "    labels = dataset['label']\n",
    "    dataset = dataset.drop(columns=['label'])\n",
    "\n",
    "    num_test_segments = 700\n",
    "    msk = np.random.randint(1, dataset.journey_number.unique()[-1], num_test_segments)\n",
    "    mask = dataset['journey_number'].isin(msk)\n",
    "\n",
    "    train_input = dataset[~mask]\n",
    "    test_input = dataset[mask]\n",
    "\n",
    "    train_labels = labels[~mask]\n",
    "    test_labels = labels[mask]\n",
    "\n",
    "    train_data = train_input.drop(columns=['journey_number'])\n",
    "    test_data = test_input.drop(columns=['journey_number'])\n",
    "\n",
    "    x_train = train_input.drop(columns=['journey_number'])\n",
    "    x_test = test_data\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pds\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import Adadelta, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [3,19,38]),\n",
      "        'Dense_1': hp.choice('Dense_1', [1,3,8,19,38]),\n",
      "        'activation': hp.choice('activation', [None, 'relu', 'sigmoid', 'tanh']),\n",
      "        'Dense_2': hp.choice('Dense_2', [1,3,8,19,38]),\n",
      "        'activation_1': hp.choice('activation_1', [None, 'relu', 'sigmoid', 'tanh']),\n",
      "        'optimizer': hp.choice('optimizer', ['Adadelta', 'Adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: data = pds.read_pickle('dataset_model2v2_w_label.pkl')\n",
      "  3: dataset = data#.iloc[0:10000]\n",
      "  4: labels = dataset['label']\n",
      "  5: dataset = dataset.drop(columns=['label'])\n",
      "  6: \n",
      "  7: num_test_segments = 700\n",
      "  8: msk = np.random.randint(1, dataset.journey_number.unique()[-1], num_test_segments)\n",
      "  9: mask = dataset['journey_number'].isin(msk)\n",
      " 10: \n",
      " 11: train_input = dataset[~mask]\n",
      " 12: test_input = dataset[mask]\n",
      " 13: \n",
      " 14: train_labels = labels[~mask]\n",
      " 15: test_labels = labels[mask]\n",
      " 16: \n",
      " 17: train_data = train_input.drop(columns=['journey_number'])\n",
      " 18: test_data = test_input.drop(columns=['journey_number'])\n",
      " 19: \n",
      " 20: x_train = train_input.drop(columns=['journey_number'])\n",
      " 21: x_test = test_data\n",
      " 22: y_train = train_labels\n",
      " 23: y_test = test_labels\n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      " 27: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \"\"\"\n",
      "   4:     Previous best:\n",
      "   5:     {'Dense': 1,\n",
      "   6:      'Dense_1': 1,\n",
      "   7:      'activation': 2,\n",
      "   8:      'activation_1': 0,\n",
      "   9:      'batch_size': 1,\n",
      "  10:      'optimizer': 2}\n",
      "  11:     \"\"\"\n",
      "  12:     model = Sequential()\n",
      "  13:     \n",
      "  14:     model.add(Dense(space['Dense'], input_shape=(19,)))\n",
      "  15:     model.add(Dense(space['Dense_1'], activation=space['activation']))\n",
      "  16:     model.add(Dense(space['Dense_2'], activation=space['activation_1']))\n",
      "  17:     model.add(Dense(1, activation='relu'))\n",
      "  18: \n",
      "  19:     model.compile(loss='mae', \n",
      "  20:                   optimizer=space['optimizer'],\n",
      "  21:                   metrics=['mae', 'mape']\n",
      "  22:                  )\n",
      "  23:     \n",
      "  24:     #result = model.fit(x_train,\n",
      "  25:     #                  y_train,\n",
      "  26:     ##                  epochs = 5,\n",
      "  27:     #                  batch_size=10,\n",
      "  28:     #                  validation_data=[x_test, y_test])\n",
      "  29:     result = model.fit(x_train, y_train,\n",
      "  30:                    batch_size=space['batch_size'],\n",
      "  31:                    epochs=3,\n",
      "  32:                    verbose=1,\n",
      "  33:                    validation_split=0.1)\n",
      "  34:     \n",
      "  35:     loss_metric = np.amax(result.history['mean_absolute_error']) \n",
      "  36:     print('Current epoch:', result.history['mean_absolute_error'], result.history['mean_absolute_percentage_error'])\n",
      "  37:     return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}\n",
      "  38: \n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 17s 7us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 16s 6us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 16s 7us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Current epoch: [57.89171174462085, 57.89171174460381, 57.89171174493684] [98.80403670588453, 98.80403670606731, 98.80403670588453]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 34s 14us/step - loss: 14.2864 - mean_absolute_error: 14.2864 - mean_absolute_percentage_error: 138469949.4919 - val_loss: 12.8074 - val_mean_absolute_error: 12.8074 - val_mean_absolute_percentage_error: 51100212.4136\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 35s 14us/step - loss: 12.5988 - mean_absolute_error: 12.5988 - mean_absolute_percentage_error: 46929879.9611 - val_loss: 12.3966 - val_mean_absolute_error: 12.3966 - val_mean_absolute_percentage_error: 32387583.9980\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 35s 14us/step - loss: 12.3405 - mean_absolute_error: 12.3405 - mean_absolute_percentage_error: 32895268.2826 - val_loss: 12.1183 - val_mean_absolute_error: 12.1183 - val_mean_absolute_percentage_error: 21317439.5829\n",
      "Current epoch: [14.286402702488378, 12.598801728882203, 12.340508075752915] [138469949.4918857, 46929879.961089015, 32895268.282608036]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 34s 14us/step - loss: 29.3736 - mean_absolute_error: 29.3736 - mean_absolute_percentage_error: 326307814.7723 - val_loss: 26.9859 - val_mean_absolute_error: 26.9859 - val_mean_absolute_percentage_error: 323647864.5658\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 34s 14us/step - loss: 15.6418 - mean_absolute_error: 15.6418 - mean_absolute_percentage_error: 149625266.5921 - val_loss: 12.0721 - val_mean_absolute_error: 12.0721 - val_mean_absolute_percentage_error: 71183948.3150\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 34s 14us/step - loss: 11.9280 - mean_absolute_error: 11.9280 - mean_absolute_percentage_error: 41543296.8625 - val_loss: 11.7326 - val_mean_absolute_error: 11.7326 - val_mean_absolute_percentage_error: 31257398.9225\n",
      "Current epoch: [29.373566939684565, 15.641754801262335, 11.927999543122098] [326307814.77230877, 149625266.59205562, 41543296.86253504]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 19s 8us/step - loss: 16.3745 - mean_absolute_error: 16.3745 - mean_absolute_percentage_error: 196193907.5430 - val_loss: 13.2842 - val_mean_absolute_error: 13.2842 - val_mean_absolute_percentage_error: 91507662.3244\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 19s 8us/step - loss: 13.0069 - mean_absolute_error: 13.0069 - mean_absolute_percentage_error: 78247378.7357 - val_loss: 12.7649 - val_mean_absolute_error: 12.7649 - val_mean_absolute_percentage_error: 72047250.4916\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 19s 8us/step - loss: 12.6874 - mean_absolute_error: 12.6874 - mean_absolute_percentage_error: 72022396.0222 - val_loss: 12.4415 - val_mean_absolute_error: 12.4415 - val_mean_absolute_percentage_error: 74570049.9002\n",
      "Current epoch: [16.37447879477261, 13.00693070291776, 12.687353154181768] [196193907.54296577, 78247378.73571621, 72022396.02218491]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 21s 8us/step - loss: 17.1939 - mean_absolute_error: 17.1939 - mean_absolute_percentage_error: 154279131.1393 - val_loss: 12.3077 - val_mean_absolute_error: 12.3077 - val_mean_absolute_percentage_error: 67808821.6807\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 20s 8us/step - loss: 12.1821 - mean_absolute_error: 12.1821 - mean_absolute_percentage_error: 52078891.8646 - val_loss: 12.0025 - val_mean_absolute_error: 12.0025 - val_mean_absolute_percentage_error: 43860630.1262\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462701/2462701 [==============================] - 20s 8us/step - loss: 11.9780 - mean_absolute_error: 11.9780 - mean_absolute_percentage_error: 36386572.2880 - val_loss: 12.0207 - val_mean_absolute_error: 12.0207 - val_mean_absolute_percentage_error: 35227473.8384\n",
      "Current epoch: [17.193899238007614, 12.182095331486094, 11.978026510885224] [154279131.13933012, 52078891.86457795, 36386572.28795758]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 18s 7us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 17s 7us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 19s 8us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Current epoch: [57.89171174458832, 57.89171174448144, 57.891711744534106] [98.80403670603943, 98.80403670603943, 98.80403670588453]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 21s 8us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 20s 8us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 20s 8us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Current epoch: [57.89171174459452, 57.891711744847, 57.89171174448144] [98.80403670588453, 98.80403670591241, 98.80403670591241]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 18s 7us/step - loss: 22.3251 - mean_absolute_error: 22.3251 - mean_absolute_percentage_error: 346228799.3791 - val_loss: 18.0088 - val_mean_absolute_error: 18.0088 - val_mean_absolute_percentage_error: 314573779.2063\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 18s 7us/step - loss: 17.9138 - mean_absolute_error: 17.9138 - mean_absolute_percentage_error: 323097689.5347 - val_loss: 17.5052 - val_mean_absolute_error: 17.5052 - val_mean_absolute_percentage_error: 311200830.3369\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 19s 8us/step - loss: 17.7400 - mean_absolute_error: 17.7400 - mean_absolute_percentage_error: 318055893.3433 - val_loss: 17.4587 - val_mean_absolute_error: 17.4587 - val_mean_absolute_percentage_error: 306980553.3145\n",
      "Current epoch: [22.325089496036384, 17.913817560110513, 17.739962125440236] [346228799.3790598, 323097689.5347328, 318055893.3432669]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 21s 9us/step - loss: 16.0652 - mean_absolute_error: 16.0652 - mean_absolute_percentage_error: 67630753.4724 - val_loss: 11.8079 - val_mean_absolute_error: 11.8079 - val_mean_absolute_percentage_error: 21253343.9116\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 20s 8us/step - loss: 11.7711 - mean_absolute_error: 11.7711 - mean_absolute_percentage_error: 19418139.4020 - val_loss: 11.5906 - val_mean_absolute_error: 11.5906 - val_mean_absolute_percentage_error: 24979797.9101\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 21s 9us/step - loss: 11.6140 - mean_absolute_error: 11.6140 - mean_absolute_percentage_error: 15682145.8487 - val_loss: 11.6325 - val_mean_absolute_error: 11.6325 - val_mean_absolute_percentage_error: 11680135.0847\n",
      "Current epoch: [16.065245482166045, 11.771076710221331, 11.613957301250355] [67630753.47237466, 19418139.401976172, 15682145.848656878]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 38s 15us/step - loss: 41.0334 - mean_absolute_error: 41.0334 - mean_absolute_percentage_error: 357190058.1897 - val_loss: 36.4491 - val_mean_absolute_error: 36.4491 - val_mean_absolute_percentage_error: 518779401.5850\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 49s 20us/step - loss: 37.1162 - mean_absolute_error: 37.1162 - mean_absolute_percentage_error: 514451102.9149 - val_loss: 36.4491 - val_mean_absolute_error: 36.4491 - val_mean_absolute_percentage_error: 518856315.2299\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 41s 17us/step - loss: 37.1162 - mean_absolute_error: 37.1162 - mean_absolute_percentage_error: 514480003.6586 - val_loss: 36.4495 - val_mean_absolute_error: 36.4495 - val_mean_absolute_percentage_error: 519207874.3626\n",
      "Current epoch: [41.03342313230812, 37.11618134027395, 37.11617919260351] [357190058.1897142, 514451102.91487974, 514480003.658598]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 29.4607 - mean_absolute_error: 29.4607 - mean_absolute_percentage_error: 288413428.4792 - val_loss: 18.9269 - val_mean_absolute_error: 18.9269 - val_mean_absolute_percentage_error: 295873493.1269\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 28s 11us/step - loss: 17.9865 - mean_absolute_error: 17.9865 - mean_absolute_percentage_error: 325837786.3425 - val_loss: 17.6649 - val_mean_absolute_error: 17.6649 - val_mean_absolute_percentage_error: 322112818.2334\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 22s 9us/step - loss: 17.7580 - mean_absolute_error: 17.7580 - mean_absolute_percentage_error: 321340667.8061 - val_loss: 17.5864 - val_mean_absolute_error: 17.5864 - val_mean_absolute_percentage_error: 329088064.9063\n",
      "Current epoch: [29.460727858734433, 17.986474442802276, 17.75799075409884] [288413428.4791747, 325837786.34250146, 321340667.8060797]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 41s 17us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 39s 16us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 41s 16us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Current epoch: [57.891711742605615, 57.891711742360876, 57.89171174221372] [98.8040367060859, 98.80403670603943, 98.80403670603943]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 25.7497 - mean_absolute_error: 25.7497 - mean_absolute_percentage_error: 158778880.7279 - val_loss: 12.1421 - val_mean_absolute_error: 12.1421 - val_mean_absolute_percentage_error: 15567041.5576\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 23s 9us/step - loss: 11.7859 - mean_absolute_error: 11.7859 - mean_absolute_percentage_error: 15509127.1744 - val_loss: 11.5174 - val_mean_absolute_error: 11.5174 - val_mean_absolute_percentage_error: 12999445.7197\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 25s 10us/step - loss: 11.5084 - mean_absolute_error: 11.5084 - mean_absolute_percentage_error: 12995812.8202 - val_loss: 11.4525 - val_mean_absolute_error: 11.4525 - val_mean_absolute_percentage_error: 13991371.2119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: [25.74972284571772, 11.785943172398394, 11.50836813862583] [158778880.72793436, 15509127.174359074, 12995812.820220195]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 14.3645 - mean_absolute_error: 14.3645 - mean_absolute_percentage_error: 168607815.7644 - val_loss: 12.9028 - val_mean_absolute_error: 12.9028 - val_mean_absolute_percentage_error: 101699971.1760\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 22s 9us/step - loss: 12.8902 - mean_absolute_error: 12.8902 - mean_absolute_percentage_error: 104425140.2678 - val_loss: 12.7440 - val_mean_absolute_error: 12.7440 - val_mean_absolute_percentage_error: 89925566.3172\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 23s 9us/step - loss: 12.7881 - mean_absolute_error: 12.7881 - mean_absolute_percentage_error: 99805353.8922 - val_loss: 12.6125 - val_mean_absolute_error: 12.6125 - val_mean_absolute_percentage_error: 98308515.5894\n",
      "Current epoch: [14.364541484000627, 12.890214508600659, 12.78813243359534] [168607815.76441938, 104425140.2677888, 99805353.89222771]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 26s 10us/step - loss: 18.2700 - mean_absolute_error: 18.2700 - mean_absolute_percentage_error: 255677689.3956 - val_loss: 14.4366 - val_mean_absolute_error: 14.4366 - val_mean_absolute_percentage_error: 142690509.2793\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 22s 9us/step - loss: 13.9255 - mean_absolute_error: 13.9255 - mean_absolute_percentage_error: 116508877.2591 - val_loss: 13.3430 - val_mean_absolute_error: 13.3430 - val_mean_absolute_percentage_error: 88496966.4848\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 22s 9us/step - loss: 13.4094 - mean_absolute_error: 13.4094 - mean_absolute_percentage_error: 84516748.8936 - val_loss: 13.3676 - val_mean_absolute_error: 13.3676 - val_mean_absolute_percentage_error: 84801312.0168\n",
      "Current epoch: [18.269970684569348, 13.925493291455663, 13.409378777932083] [255677689.3955868, 116508877.25910814, 84516748.89356174]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 25s 10us/step - loss: 13.9836 - mean_absolute_error: 13.9836 - mean_absolute_percentage_error: 98596466.8353 - val_loss: 12.0319 - val_mean_absolute_error: 12.0319 - val_mean_absolute_percentage_error: 25775541.1113\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 11.9729 - mean_absolute_error: 11.9729 - mean_absolute_percentage_error: 23220807.4832 - val_loss: 11.7899 - val_mean_absolute_error: 11.7899 - val_mean_absolute_percentage_error: 21371349.5645\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 23s 9us/step - loss: 11.8054 - mean_absolute_error: 11.8054 - mean_absolute_percentage_error: 20257613.0784 - val_loss: 11.6765 - val_mean_absolute_error: 11.6765 - val_mean_absolute_percentage_error: 23920886.6937\n",
      "Current epoch: [13.983640446039333, 11.972868217865166, 11.805449901252565] [98596466.83529502, 23220807.48320937, 20257613.078375388]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 23.7542 - mean_absolute_error: 23.7542 - mean_absolute_percentage_error: 342033373.0029 - val_loss: 17.6902 - val_mean_absolute_error: 17.6902 - val_mean_absolute_percentage_error: 321652227.0558\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 17.7792 - mean_absolute_error: 17.7792 - mean_absolute_percentage_error: 317153580.2222 - val_loss: 17.6834 - val_mean_absolute_error: 17.6834 - val_mean_absolute_percentage_error: 304988632.4787\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 22s 9us/step - loss: 17.7781 - mean_absolute_error: 17.7781 - mean_absolute_percentage_error: 316902860.6699 - val_loss: 17.6730 - val_mean_absolute_error: 17.6730 - val_mean_absolute_percentage_error: 322848579.8762\n",
      "Current epoch: [23.754163888304728, 17.779167196121453, 17.77812523652283] [342033373.00288725, 317153580.2221756, 316902860.66991144]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 2/3\n",
      "2462701/2462701 [==============================] - 23s 9us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Epoch 3/3\n",
      "2462701/2462701 [==============================] - 24s 10us/step - loss: 57.8917 - mean_absolute_error: 57.8917 - mean_absolute_percentage_error: 98.8040 - val_loss: 57.0621 - val_mean_absolute_error: 57.0621 - val_mean_absolute_percentage_error: 98.7940\n",
      "Current epoch: [57.89171174463944, 57.89171174472463, 57.89171174482067] [98.80403670591241, 98.80403670588453, 98.80403670588453]\n",
      "Train on 2462701 samples, validate on 273634 samples\n",
      "Epoch 1/3\n",
      "2462701/2462701 [==============================] - 25s 10us/step - loss: 14.2754 - mean_absolute_error: 14.2754 - mean_absolute_percentage_error: 164974060.4475 - val_loss: 12.4811 - val_mean_absolute_error: 12.4811 - val_mean_absolute_percentage_error: 83548830.3769\n",
      "Epoch 2/3\n",
      "1172992/2462701 [=============>................] - ETA: 12s - loss: 12.4276 - mean_absolute_error: 12.4276 - mean_absolute_percentage_error: 82986051.6255"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=20,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name=\"Model2v2HPO\"\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
