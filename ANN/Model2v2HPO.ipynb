{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, still in the process of experimenting with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pds\n",
    "from tensorflow import keras\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "        \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(19, input_shape=(19,)))\n",
    "    model.add(Dense({{choice([3,8,19])}}, activation={{choice(['relu', 'sigmoid', 'tanh'])}}))\n",
    "    model.add(Dense({{choice([3,8,19])}}, activation={{choice(['relu', 'sigmoid', 'tanh'])}}))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mae', \n",
    "                  optimizer={{choice(['RMSProp', 'Adadelta', 'Adam', 'sgd'])}},\n",
    "                  metrics=['mae', 'mape']\n",
    "                 )\n",
    "    \n",
    "    #result = model.fit(x_train,\n",
    "    #                  y_train,\n",
    "    ##                  epochs = 5,\n",
    "    #                  batch_size=10,\n",
    "    #                  validation_data=[x_test, y_test])\n",
    "    result = model.fit(x_train, y_train,\n",
    "                   batch_size={{choice([64, 128])}},\n",
    "                   epochs=5,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.1)\n",
    "    \n",
    "    loss_metric = np.amax(result.history['mean_absolute_error']) \n",
    "    print('Current epoch:', result.history['mean_absolute_error'], result.history['mean_absolute_percentage_error'])\n",
    "    return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    data = pds.read_pickle('dataset_model2v2_w_label.pkl')\n",
    "    dataset = data#.iloc[0:10000]\n",
    "    labels = dataset['label']\n",
    "    dataset = dataset.drop(columns=['label'])\n",
    "\n",
    "    num_test_segments = 700\n",
    "    msk = np.random.randint(1, dataset.journey_number.unique()[-1], num_test_segments)\n",
    "    mask = dataset['journey_number'].isin(msk)\n",
    "\n",
    "    train_input = dataset[~mask]\n",
    "    test_input = dataset[mask]\n",
    "\n",
    "    train_labels = labels[~mask]\n",
    "    test_labels = labels[mask]\n",
    "\n",
    "    train_data = train_input.drop(columns=['journey_number'])\n",
    "    test_data = test_input.drop(columns=['journey_number'])\n",
    "\n",
    "    x_train = train_input.drop(columns=['journey_number'])\n",
    "    x_test = test_data\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pds\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import Adadelta, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [3,8,19]),\n",
      "        'activation': hp.choice('activation', ['relu', 'sigmoid']),\n",
      "        'optimizer': hp.choice('optimizer', ['RMSProp', 'Adadelta']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: data = pds.read_pickle('dataset_model2v2_w_label.pkl')\n",
      "  3: dataset = data#.iloc[0:10000]\n",
      "  4: labels = dataset['label']\n",
      "  5: dataset = dataset.drop(columns=['label'])\n",
      "  6: \n",
      "  7: num_test_segments = 700\n",
      "  8: msk = np.random.randint(1, dataset.journey_number.unique()[-1], num_test_segments)\n",
      "  9: mask = dataset['journey_number'].isin(msk)\n",
      " 10: \n",
      " 11: train_input = dataset[~mask]\n",
      " 12: test_input = dataset[mask]\n",
      " 13: \n",
      " 14: train_labels = labels[~mask]\n",
      " 15: test_labels = labels[mask]\n",
      " 16: \n",
      " 17: train_data = train_input.drop(columns=['journey_number'])\n",
      " 18: test_data = test_input.drop(columns=['journey_number'])\n",
      " 19: \n",
      " 20: x_train = train_input.drop(columns=['journey_number'])\n",
      " 21: x_test = test_data\n",
      " 22: y_train = train_labels\n",
      " 23: y_test = test_labels\n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      " 27: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:         \n",
      "   4:     model = Sequential()\n",
      "   5:     \n",
      "   6:     model.add(Dense(19, input_shape=(19,)))\n",
      "   7:     model.add(Dense(space['Dense'], activation=space['activation']))\n",
      "   8:     model.add(Dense(1, activation='relu'))\n",
      "   9: \n",
      "  10:     model.compile(loss='mae', \n",
      "  11:                   optimizer=space['optimizer'],\n",
      "  12:                   metrics=['mae', 'mape']\n",
      "  13:                  )\n",
      "  14:     \n",
      "  15:     #result = model.fit(x_train,\n",
      "  16:     #                  y_train,\n",
      "  17:     ##                  epochs = 5,\n",
      "  18:     #                  batch_size=10,\n",
      "  19:     #                  validation_data=[x_test, y_test])\n",
      "  20:     result = model.fit(x_train, y_train,\n",
      "  21:                    batch_size=space['batch_size'],\n",
      "  22:                    epochs=5,\n",
      "  23:                    verbose=1,\n",
      "  24:                    validation_split=0.1)\n",
      "  25:     \n",
      "  26:     loss_metric = np.amax(result.history['mean_absolute_error']) \n",
      "  27:     print('Current epoch:', result.history['mean_absolute_error'], result.history['mean_absolute_percentage_error'])\n",
      "  28:     return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}\n",
      "  29: \n",
      "Train on 2455323 samples, validate on 272814 samples\n",
      "Epoch 1/5\n",
      "2455323/2455323 [==============================] - 16s 7us/step - loss: 15.7959 - mean_absolute_error: 15.7959 - mean_absolute_percentage_error: 184750420.4366 - val_loss: 12.7745 - val_mean_absolute_error: 12.7745 - val_mean_absolute_percentage_error: 60966081.5274\n",
      "Epoch 2/5\n",
      "2455323/2455323 [==============================] - 16s 7us/step - loss: 12.2394 - mean_absolute_error: 12.2394 - mean_absolute_percentage_error: 47372881.1735 - val_loss: 12.3525 - val_mean_absolute_error: 12.3525 - val_mean_absolute_percentage_error: 45080059.4973\n",
      "Epoch 3/5\n",
      "2455323/2455323 [==============================] - 16s 7us/step - loss: 12.0655 - mean_absolute_error: 12.0655 - mean_absolute_percentage_error: 38122687.7166 - val_loss: 12.6219 - val_mean_absolute_error: 12.6219 - val_mean_absolute_percentage_error: 54311438.3687\n",
      "Epoch 4/5\n",
      "2455323/2455323 [==============================] - 16s 7us/step - loss: 11.9834 - mean_absolute_error: 11.9834 - mean_absolute_percentage_error: 34558382.1550 - val_loss: 12.2118 - val_mean_absolute_error: 12.2118 - val_mean_absolute_percentage_error: 39766887.0739\n",
      "Epoch 5/5\n",
      "2455323/2455323 [==============================] - 16s 7us/step - loss: 11.9294 - mean_absolute_error: 11.9294 - mean_absolute_percentage_error: 30958446.4986 - val_loss: 12.2448 - val_mean_absolute_error: 12.2448 - val_mean_absolute_percentage_error: 35875952.8152\n",
      "Current epoch: [15.795904634263692, 12.2394168803894, 12.065458227341272, 11.983368326986835, 11.929433704930892] [184750420.43660975, 47372881.17350449, 38122687.716587864, 34558382.15503373, 30958446.498586968]\n",
      "Train on 2455323 samples, validate on 272814 samples\n",
      "Epoch 1/5\n",
      "2455323/2455323 [==============================] - 29s 12us/step - loss: 38.8516 - mean_absolute_error: 38.8516 - mean_absolute_percentage_error: 442454700.3417 - val_loss: 36.7488 - val_mean_absolute_error: 36.7488 - val_mean_absolute_percentage_error: 520308993.4333\n",
      "Epoch 2/5\n",
      "2455323/2455323 [==============================] - 29s 12us/step - loss: 36.9722 - mean_absolute_error: 36.9722 - mean_absolute_percentage_error: 514345718.1965 - val_loss: 36.7494 - val_mean_absolute_error: 36.7494 - val_mean_absolute_percentage_error: 520860752.6940\n",
      "Epoch 3/5\n",
      "2455323/2455323 [==============================] - 29s 12us/step - loss: 33.5668 - mean_absolute_error: 33.5668 - mean_absolute_percentage_error: 474754334.5041 - val_loss: 21.0702 - val_mean_absolute_error: 21.0702 - val_mean_absolute_percentage_error: 368736562.3065\n",
      "Epoch 4/5\n",
      "2455323/2455323 [==============================] - 28s 11us/step - loss: 16.3980 - mean_absolute_error: 16.3980 - mean_absolute_percentage_error: 277793190.3114 - val_loss: 14.5769 - val_mean_absolute_error: 14.5769 - val_mean_absolute_percentage_error: 189589644.5526\n",
      "Epoch 5/5\n",
      "2455323/2455323 [==============================] - 28s 11us/step - loss: 14.1687 - mean_absolute_error: 14.1687 - mean_absolute_percentage_error: 166598003.3407 - val_loss: 14.2146 - val_mean_absolute_error: 14.2146 - val_mean_absolute_percentage_error: 151444936.7159\n",
      "Current epoch: [38.851585476421235, 36.9721863948252, 33.56682892501822, 16.39803383441953, 14.16869177083252] [442454700.34167576, 514345718.1964734, 474754334.50414914, 277793190.31140536, 166598003.34070513]\n",
      "Train on 2455323 samples, validate on 272814 samples\n",
      "Epoch 1/5\n",
      "2455323/2455323 [==============================] - 31s 13us/step - loss: 15.2443 - mean_absolute_error: 15.2443 - mean_absolute_percentage_error: 174731049.0000 - val_loss: 13.8889 - val_mean_absolute_error: 13.8889 - val_mean_absolute_percentage_error: 76115120.3619\n",
      "Epoch 2/5\n",
      "2455323/2455323 [==============================] - 31s 13us/step - loss: 13.2703 - mean_absolute_error: 13.2703 - mean_absolute_percentage_error: 71408238.9977 - val_loss: 13.5889 - val_mean_absolute_error: 13.5889 - val_mean_absolute_percentage_error: 84270693.5291\n",
      "Epoch 3/5\n",
      "2455323/2455323 [==============================] - 31s 13us/step - loss: 13.1164 - mean_absolute_error: 13.1164 - mean_absolute_percentage_error: 66224596.6477 - val_loss: 13.2521 - val_mean_absolute_error: 13.2521 - val_mean_absolute_percentage_error: 68448287.7871\n",
      "Epoch 4/5\n",
      "2455323/2455323 [==============================] - 31s 13us/step - loss: 13.0828 - mean_absolute_error: 13.0828 - mean_absolute_percentage_error: 65381953.8026 - val_loss: 13.2240 - val_mean_absolute_error: 13.2240 - val_mean_absolute_percentage_error: 62199237.7053\n",
      "Epoch 5/5\n",
      "2455323/2455323 [==============================] - 31s 13us/step - loss: 13.0668 - mean_absolute_error: 13.0668 - mean_absolute_percentage_error: 65063989.3896 - val_loss: 13.2218 - val_mean_absolute_error: 13.2218 - val_mean_absolute_percentage_error: 59276412.1903\n",
      "Current epoch: [15.244345409938859, 13.2702862772931, 13.116395659487699, 13.082803442437239, 13.066794411276465] [174731049.00004083, 71408238.9976522, 66224596.64769761, 65381953.802583575, 65063989.38957858]\n",
      "Train on 2455323 samples, validate on 272814 samples\n",
      "Epoch 1/5\n",
      "2455323/2455323 [==============================] - 17s 7us/step - loss: 21.7322 - mean_absolute_error: 21.7322 - mean_absolute_percentage_error: 210037433.4162 - val_loss: 14.3841 - val_mean_absolute_error: 14.3841 - val_mean_absolute_percentage_error: 127229157.8077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "2455323/2455323 [==============================] - 17s 7us/step - loss: 13.7553 - mean_absolute_error: 13.7553 - mean_absolute_percentage_error: 117576439.3197 - val_loss: 13.6692 - val_mean_absolute_error: 13.6692 - val_mean_absolute_percentage_error: 108042717.6554\n",
      "Epoch 3/5\n",
      "2455323/2455323 [==============================] - 17s 7us/step - loss: 13.3673 - mean_absolute_error: 13.3673 - mean_absolute_percentage_error: 107886383.2500 - val_loss: 13.4616 - val_mean_absolute_error: 13.4616 - val_mean_absolute_percentage_error: 106881481.5051\n",
      "Epoch 4/5\n",
      "2455323/2455323 [==============================] - 17s 7us/step - loss: 13.2281 - mean_absolute_error: 13.2281 - mean_absolute_percentage_error: 102945290.7834 - val_loss: 13.3634 - val_mean_absolute_error: 13.3634 - val_mean_absolute_percentage_error: 97792548.2775\n",
      "Epoch 5/5\n",
      "2455323/2455323 [==============================] - 17s 7us/step - loss: 13.1480 - mean_absolute_error: 13.1480 - mean_absolute_percentage_error: 98707999.1067 - val_loss: 13.4024 - val_mean_absolute_error: 13.4024 - val_mean_absolute_percentage_error: 95680133.1587\n",
      "Current epoch: [21.73220395049927, 13.755278590047368, 13.367264034160389, 13.228143356152612, 13.14796187922834] [210037433.4162181, 117576439.31968974, 107886383.25003766, 102945290.78341338, 98707999.10665725]\n",
      "Train on 2455323 samples, validate on 272814 samples\n",
      "Epoch 1/5\n",
      "2455323/2455323 [==============================] - 32s 13us/step - loss: 57.7518 - mean_absolute_error: 57.7518 - mean_absolute_percentage_error: 98.8045 - val_loss: 57.3114 - val_mean_absolute_error: 57.3114 - val_mean_absolute_percentage_error: 98.7900\n",
      "Epoch 2/5\n",
      "2455323/2455323 [==============================] - 32s 13us/step - loss: 57.7518 - mean_absolute_error: 57.7518 - mean_absolute_percentage_error: 98.8045 - val_loss: 57.3114 - val_mean_absolute_error: 57.3114 - val_mean_absolute_percentage_error: 98.7900\n",
      "Epoch 3/5\n",
      "2455323/2455323 [==============================] - 32s 13us/step - loss: 57.7518 - mean_absolute_error: 57.7518 - mean_absolute_percentage_error: 98.8045 - val_loss: 57.3114 - val_mean_absolute_error: 57.3114 - val_mean_absolute_percentage_error: 98.7900\n",
      "Epoch 4/5\n",
      "2455323/2455323 [==============================] - 32s 13us/step - loss: 57.7518 - mean_absolute_error: 57.7518 - mean_absolute_percentage_error: 98.8045 - val_loss: 57.3114 - val_mean_absolute_error: 57.3114 - val_mean_absolute_percentage_error: 98.7900\n",
      "Epoch 5/5\n",
      "2455323/2455323 [==============================] - 32s 13us/step - loss: 57.7518 - mean_absolute_error: 57.7518 - mean_absolute_percentage_error: 98.8045 - val_loss: 57.3114 - val_mean_absolute_error: 57.3114 - val_mean_absolute_percentage_error: 98.7900\n",
      "Current epoch: [57.751782637216024, 57.751782637214475, 57.75178263752675, 57.751782636830725, 57.75178263721292] [98.80451573988432, 98.8045157398719, 98.80451573988432, 98.80451573985947, 98.80451573988432]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name=\"Model2v2HPO\"\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': 0, 'activation': 0, 'batch_size': 0, 'optimizer': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x26896195a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
