{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, still in the process of experimenting with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pds\n",
    "from tensorflow import keras\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "        \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(19, input_shape=(19,)))\n",
    "    model.add(Dense({{choice([3,8,19])}}, activation={{choice(['relu', 'sigmoid', 'tanh'])}}))\n",
    "    model.add(Dense({{choice([3,8,19])}}, activation={{choice(['relu', 'sigmoid', 'tanh'])}}))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mae', \n",
    "                  optimizer={{choice(['RMSProp', 'Adadelta', 'Adam', 'sgd'])}},\n",
    "                  metrics=['mae', 'mape']\n",
    "                 )\n",
    "    \n",
    "    #result = model.fit(x_train,\n",
    "    #                  y_train,\n",
    "    ##                  epochs = 5,\n",
    "    #                  batch_size=10,\n",
    "    #                  validation_data=[x_test, y_test])\n",
    "    result = model.fit(x_train, y_train,\n",
    "                   batch_size={{choice([64, 128])}},\n",
    "                   epochs=5,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.1)\n",
    "    \n",
    "    loss_metric = np.amax(result.history['mean_absolute_error']) \n",
    "    print('Current epoch:', result.history['mean_absolute_error'], result.history['mean_absolute_percentage_error'])\n",
    "    return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    data = pds.read_pickle('dataset_model2v2_w_label.pkl')\n",
    "    dataset = data#.iloc[0:10000]\n",
    "    labels = dataset['label']\n",
    "    dataset = dataset.drop(columns=['label'])\n",
    "\n",
    "    num_test_segments = 700\n",
    "    msk = np.random.randint(1, dataset.journey_number.unique()[-1], num_test_segments)\n",
    "    mask = dataset['journey_number'].isin(msk)\n",
    "\n",
    "    train_input = dataset[~mask]\n",
    "    test_input = dataset[mask]\n",
    "\n",
    "    train_labels = labels[~mask]\n",
    "    test_labels = labels[mask]\n",
    "\n",
    "    train_data = train_input.drop(columns=['journey_number'])\n",
    "    test_data = test_input.drop(columns=['journey_number'])\n",
    "\n",
    "    x_train = train_input.drop(columns=['journey_number'])\n",
    "    x_test = test_data\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pds\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import Adadelta, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [3,8,19]),\n",
      "        'activation': hp.choice('activation', ['relu', 'sigmoid', 'tanh']),\n",
      "        'Dense_1': hp.choice('Dense_1', [3,8,19]),\n",
      "        'activation_1': hp.choice('activation_1', ['relu', 'sigmoid', 'tanh']),\n",
      "        'optimizer': hp.choice('optimizer', ['RMSProp', 'Adadelta', 'Adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: data = pds.read_pickle('dataset_model2v2_w_label.pkl')\n",
      "  3: dataset = data#.iloc[0:10000]\n",
      "  4: labels = dataset['label']\n",
      "  5: dataset = dataset.drop(columns=['label'])\n",
      "  6: \n",
      "  7: num_test_segments = 700\n",
      "  8: msk = np.random.randint(1, dataset.journey_number.unique()[-1], num_test_segments)\n",
      "  9: mask = dataset['journey_number'].isin(msk)\n",
      " 10: \n",
      " 11: train_input = dataset[~mask]\n",
      " 12: test_input = dataset[mask]\n",
      " 13: \n",
      " 14: train_labels = labels[~mask]\n",
      " 15: test_labels = labels[mask]\n",
      " 16: \n",
      " 17: train_data = train_input.drop(columns=['journey_number'])\n",
      " 18: test_data = test_input.drop(columns=['journey_number'])\n",
      " 19: \n",
      " 20: x_train = train_input.drop(columns=['journey_number'])\n",
      " 21: x_test = test_data\n",
      " 22: y_train = train_labels\n",
      " 23: y_test = test_labels\n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      " 27: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:         \n",
      "   4:     model = Sequential()\n",
      "   5:     \n",
      "   6:     model.add(Dense(19, input_shape=(19,)))\n",
      "   7:     model.add(Dense(space['Dense'], activation=space['activation']))\n",
      "   8:     model.add(Dense(space['Dense_1'], activation=space['activation_1']))\n",
      "   9:     model.add(Dense(1, activation='relu'))\n",
      "  10: \n",
      "  11:     model.compile(loss='mae', \n",
      "  12:                   optimizer=space['optimizer'],\n",
      "  13:                   metrics=['mae', 'mape']\n",
      "  14:                  )\n",
      "  15:     \n",
      "  16:     #result = model.fit(x_train,\n",
      "  17:     #                  y_train,\n",
      "  18:     ##                  epochs = 5,\n",
      "  19:     #                  batch_size=10,\n",
      "  20:     #                  validation_data=[x_test, y_test])\n",
      "  21:     result = model.fit(x_train, y_train,\n",
      "  22:                    batch_size=space['batch_size'],\n",
      "  23:                    epochs=5,\n",
      "  24:                    verbose=1,\n",
      "  25:                    validation_split=0.1)\n",
      "  26:     \n",
      "  27:     loss_metric = np.amax(result.history['mean_absolute_error']) \n",
      "  28:     print('Current epoch:', result.history['mean_absolute_error'], result.history['mean_absolute_percentage_error'])\n",
      "  29:     return {'loss': loss_metric, 'status': STATUS_OK, 'model': model}\n",
      "  30: \n",
      "Train on 2458262 samples, validate on 273141 samples\n",
      "Epoch 1/5\n",
      "2458262/2458262 [==============================] - 19s 8us/step - loss: 14.6208 - mean_absolute_error: 14.6208 - mean_absolute_percentage_error: 95535218.4993 - val_loss: 12.5683 - val_mean_absolute_error: 12.5683 - val_mean_absolute_percentage_error: 34146066.5392\n",
      "Epoch 2/5\n",
      "2458262/2458262 [==============================] - 17s 7us/step - loss: 12.2460 - mean_absolute_error: 12.2460 - mean_absolute_percentage_error: 33292719.7703 - val_loss: 12.5116 - val_mean_absolute_error: 12.5116 - val_mean_absolute_percentage_error: 31947144.9831\n",
      "Epoch 3/5\n",
      "2458262/2458262 [==============================] - 17s 7us/step - loss: 12.1261 - mean_absolute_error: 12.1261 - mean_absolute_percentage_error: 31938632.1588 - val_loss: 12.3536 - val_mean_absolute_error: 12.3536 - val_mean_absolute_percentage_error: 29683233.7014\n",
      "Epoch 4/5\n",
      "2458262/2458262 [==============================] - 17s 7us/step - loss: 12.0634 - mean_absolute_error: 12.0634 - mean_absolute_percentage_error: 30966462.9618 - val_loss: 12.2833 - val_mean_absolute_error: 12.2833 - val_mean_absolute_percentage_error: 33274113.0947\n",
      "Epoch 5/5\n",
      "2458262/2458262 [==============================] - 17s 7us/step - loss: 12.0391 - mean_absolute_error: 12.0391 - mean_absolute_percentage_error: 30392152.6657 - val_loss: 12.5168 - val_mean_absolute_error: 12.5168 - val_mean_absolute_percentage_error: 43565437.6838\n",
      "Current epoch: [14.62083510979738, 12.245964390103131, 12.126137776572751, 12.063427376568152, 12.039051072835864] [95535218.49933185, 33292719.770327587, 31938632.158752125, 30966462.961844806, 30392152.665711593]\n",
      "Train on 2458262 samples, validate on 273141 samples\n",
      "Epoch 1/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 37.3236 - mean_absolute_error: 37.3236 - mean_absolute_percentage_error: 493114207.0048 - val_loss: 27.8738 - val_mean_absolute_error: 27.8738 - val_mean_absolute_percentage_error: 354720705.1781\n",
      "Epoch 2/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 13.9212 - mean_absolute_error: 13.9212 - mean_absolute_percentage_error: 107932747.0850 - val_loss: 12.9194 - val_mean_absolute_error: 12.9194 - val_mean_absolute_percentage_error: 83869019.9575\n",
      "Epoch 3/5\n",
      "2458262/2458262 [==============================] - 35s 14us/step - loss: 12.1474 - mean_absolute_error: 12.1474 - mean_absolute_percentage_error: 51417437.6791 - val_loss: 12.3985 - val_mean_absolute_error: 12.3985 - val_mean_absolute_percentage_error: 41864811.2549\n",
      "Epoch 4/5\n",
      "2458262/2458262 [==============================] - 32s 13us/step - loss: 11.9771 - mean_absolute_error: 11.9771 - mean_absolute_percentage_error: 42736058.2777 - val_loss: 12.7001 - val_mean_absolute_error: 12.7001 - val_mean_absolute_percentage_error: 61087360.9671\n",
      "Epoch 5/5\n",
      "2458262/2458262 [==============================] - 32s 13us/step - loss: 11.8838 - mean_absolute_error: 11.8838 - mean_absolute_percentage_error: 36499372.9490 - val_loss: 12.0885 - val_mean_absolute_error: 12.0885 - val_mean_absolute_percentage_error: 30300195.3845\n",
      "Current epoch: [37.323583101453295, 13.92116128940152, 12.14743057744215, 11.977085049387735, 11.883780818501888] [493114207.0048336, 107932747.08502936, 51417437.67912186, 42736058.27771926, 36499372.949044704]\n",
      "Train on 2458262 samples, validate on 273141 samples\n",
      "Epoch 1/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 15.0263 - mean_absolute_error: 15.0263 - mean_absolute_percentage_error: 70551271.8345 - val_loss: 12.3500 - val_mean_absolute_error: 12.3500 - val_mean_absolute_percentage_error: 20300945.5650\n",
      "Epoch 2/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 11.8613 - mean_absolute_error: 11.8613 - mean_absolute_percentage_error: 16903015.0882 - val_loss: 12.0143 - val_mean_absolute_error: 12.0143 - val_mean_absolute_percentage_error: 16561763.6747\n",
      "Epoch 3/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 11.6737 - mean_absolute_error: 11.6737 - mean_absolute_percentage_error: 14550412.4618 - val_loss: 12.0861 - val_mean_absolute_error: 12.0861 - val_mean_absolute_percentage_error: 23248171.0523\n",
      "Epoch 4/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 11.5823 - mean_absolute_error: 11.5823 - mean_absolute_percentage_error: 13466381.6586 - val_loss: 11.7785 - val_mean_absolute_error: 11.7785 - val_mean_absolute_percentage_error: 8644439.1831\n",
      "Epoch 5/5\n",
      "2458262/2458262 [==============================] - 34s 14us/step - loss: 11.5354 - mean_absolute_error: 11.5354 - mean_absolute_percentage_error: 13390119.3155 - val_loss: 11.7450 - val_mean_absolute_error: 11.7450 - val_mean_absolute_percentage_error: 9163349.9151\n",
      "Current epoch: [15.026315116628297, 11.86125396535866, 11.673746268866829, 11.58234593335859, 11.535378221440245] [70551271.83449455, 16903015.088186856, 14550412.461769618, 13466381.658634406, 13390119.315541957]\n",
      "Train on 2458262 samples, validate on 273141 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2458262/2458262 [==============================] - 17s 7us/step - loss: 57.7815 - mean_absolute_error: 57.7815 - mean_absolute_percentage_error: 98.8031 - val_loss: 57.6001 - val_mean_absolute_error: 57.6001 - val_mean_absolute_percentage_error: 98.7988\n",
      "Epoch 2/5\n",
      "2458262/2458262 [==============================] - 18s 7us/step - loss: 57.7815 - mean_absolute_error: 57.7815 - mean_absolute_percentage_error: 98.8031 - val_loss: 57.6001 - val_mean_absolute_error: 57.6001 - val_mean_absolute_percentage_error: 98.7988\n",
      "Epoch 3/5\n",
      "2458262/2458262 [==============================] - 19s 8us/step - loss: 57.7815 - mean_absolute_error: 57.7815 - mean_absolute_percentage_error: 98.8031 - val_loss: 57.6001 - val_mean_absolute_error: 57.6001 - val_mean_absolute_percentage_error: 98.7988\n",
      "Epoch 4/5\n",
      "2458262/2458262 [==============================] - 18s 7us/step - loss: 57.7815 - mean_absolute_error: 57.7815 - mean_absolute_percentage_error: 98.8031 - val_loss: 57.6001 - val_mean_absolute_error: 57.6001 - val_mean_absolute_percentage_error: 98.7988\n",
      "Epoch 5/5\n",
      "2458262/2458262 [==============================] - 18s 7us/step - loss: 57.7815 - mean_absolute_error: 57.7815 - mean_absolute_percentage_error: 98.8031 - val_loss: 57.6001 - val_mean_absolute_error: 57.6001 - val_mean_absolute_percentage_error: 98.7988\n",
      "Current epoch: [57.78153675499796, 57.78153675460691, 57.78153675499485, 57.78153675501969, 57.78153675443001] [98.80313815207654, 98.80313815206414, 98.80313815206414, 98.80313815207654, 98.80313815206414]\n",
      "Train on 2458262 samples, validate on 273141 samples\n",
      "Epoch 1/5\n",
      "2458262/2458262 [==============================] - 30s 12us/step - loss: 14.7472 - mean_absolute_error: 14.7472 - mean_absolute_percentage_error: 71127466.6965 - val_loss: 12.3305 - val_mean_absolute_error: 12.3305 - val_mean_absolute_percentage_error: 28106257.3230\n",
      "Epoch 2/5\n",
      "2458262/2458262 [==============================] - 30s 12us/step - loss: 11.9047 - mean_absolute_error: 11.9047 - mean_absolute_percentage_error: 18949269.0239 - val_loss: 12.1631 - val_mean_absolute_error: 12.1631 - val_mean_absolute_percentage_error: 10512084.7775\n",
      "Epoch 3/5\n",
      "2458262/2458262 [==============================] - 30s 12us/step - loss: 11.8055 - mean_absolute_error: 11.8055 - mean_absolute_percentage_error: 17046763.6853 - val_loss: 12.7121 - val_mean_absolute_error: 12.7121 - val_mean_absolute_percentage_error: 18458551.7129\n",
      "Epoch 4/5\n",
      "2458262/2458262 [==============================] - 30s 12us/step - loss: 11.7462 - mean_absolute_error: 11.7462 - mean_absolute_percentage_error: 16041391.7376 - val_loss: 12.2398 - val_mean_absolute_error: 12.2398 - val_mean_absolute_percentage_error: 21544671.4563\n",
      "Epoch 5/5\n",
      "2458262/2458262 [==============================] - 30s 12us/step - loss: 11.7029 - mean_absolute_error: 11.7029 - mean_absolute_percentage_error: 14822862.7143 - val_loss: 11.8079 - val_mean_absolute_error: 11.8079 - val_mean_absolute_percentage_error: 14216336.1230\n",
      "Current epoch: [14.747237793165286, 11.904700697335947, 11.805476622532131, 11.746240577313097, 11.702891842460186] [71127466.69652824, 18949269.023937915, 17046763.685340997, 16041391.737580432, 14822862.714318335]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name=\"Model2v2HPO\"\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': 1,\n",
       " 'Dense_1': 1,\n",
       " 'activation': 2,\n",
       " 'activation_1': 0,\n",
       " 'batch_size': 1,\n",
       " 'optimizer': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-99c6dbb46c12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jacke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m   1752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jacke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m       \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[0mis_x_eager_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jacke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[1;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[0;32m    892\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[0;32m    893\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[1;32m--> 894\u001b[1;33m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[0;32m    895\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "best_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
