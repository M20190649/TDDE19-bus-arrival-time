%%% lorem.tex --- 
%% 
%% Filename: lorem.tex
%% Description: 
%% Author: Ola Leifler
%% Maintainer: 
%% Created: Wed Nov 10 09:59:23 2010 (CET)
%% Version: $Id$
%% Version: 
%% Last-Updated: Wed Nov 10 09:59:47 2010 (CET)
%%           By: Ola Leifler
%%     Update #: 2
%% URL: 
%% Keywords: 
%% Compatibility: 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Commentary: 
%% 
%% 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Change log:
%% 
%% 
%% RCS $Log$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Code:

\chapter{Discussion}
\label{cha:discussion}

This chapter start out with a discussion of the results of the project, followed by discussions of the chosen methods. Lastly there are some suggestions for future work.

\section{Results}
\label{sec:discussion-results} 
There are differences in the datasets due to the division of the 20\%, 40\%, 60\% and 80\% sections being done after stop-compression. This results in that the 20\% division in a stop-compressed trajectory is further into the journey than in a trajectory that is not stop-compressed. If the data was split on timestamp that would not differ, but, since the data is split by index, it does. This, most likely, has an effect on the results and therefore models trained on stop-compressed data cannot really be compared to models trained on data that was not stop-compressed in a meaningful way. If the stop-compression had been done after the split, the results would have been more reasonable to compare.

As can be seen in table \ref{tbl:models-mae-and-mape-203}, the neural networks performed best in terms of both MAE and MAPE, on both the regular data and the stop-compressed data. The baseline method and M1 is on par, and their MAPE increases greatly when predicting on smaller parts of the segment. For the 80\% prediction, the predicted time left is larger than the actual time left, yielding an MAPE above 100\%. The GPR performs quite poorly in comparison to the neural network models.

When considering the evaluation segment-wise (see table \ref{tbl:model-mae-of-segs-203}), the neural network approaches also dominates. The models trained on stop-compressed data yields the best results in terms of MAE, especially M2 and M3. Table \ref{fig:model-mape-of-segs-203} shows that in relative terms, the models trained on non-compressed data sometimes yields better results. This is probably due to the differences in the trajectory splits described previously. However, M2 and M3 still outperforms the other models,  except for M4 which excels on non-compressed data.

In terms of complexity, the neural networks require much less resources than the implemented GPR model in order to make a prediction, and the GPR will become even more expensive given more trajectories to compare with. The GPR would however, most likely, improve its performance given more trajectories. There are methods, such as using inducing points, that could decrease GPR resource consumption.

The only models that were evaluated for bus line 11 were the baseline method and M4. M4 performs better than the baseline on all metrics and all segments. 

\section{Method}
This section contains method specific discussion.

\label{sec:discussion-method}
\subsection{Evaluation Methods}
There a two main differences in the methods that were used. The baseline method and the M1 model make predictions on complete segments. These two models does not have the capability of making sophisticated predictions within a segment. Therefore intra-segment predictions are made by subtracting the time spent on the segment from the time predicted for the whole segment. This leads to an increased MAPE as the prediction error remains constant, but when using less and less distance to predict on, the constant error corresponds to a larger part of the sub-segment.

\subsection{Neural Networks}
The neural networks that were trained and evaluated on stop-compressed data performed much better overall with regards to both MAE and MAPE. This was expected since the stop-compression removes most of the data points observed during dwell time when the bus is standing still, which is the main source of error for the models using non-compressed data. 

A likely reason for why M4 outperformed M2 and M3 using the non-compressed data is that M4 managed to capture the dwell time better than the other models, although dwell time is still the main cause of error for this model. Due to hardware limitations, the longest sequence that could be used as input for M4 was 20 data points. It would be interesting to know if longer sequences would yield better results.

The neural networks seem to be able to generalize to other bus lines fairly well even though the network parameters have been tuned specifically for line three. Comparing the MAPE for bus line three and eleven in tables \ref{tbl:models-mae-and-mape-203} and \ref{tbl:models-mae-and-mape-211} it can be seen that it is a bit higher for bus eleven, although this was expected since that bus travels through areas with heavy traffic which would likely be hard for the model to capture.

\subsection{Kalman filtering}
A Kalman filter was applied to all NN models but without improving the performance. This was due to the models constantly overpredicting or underpredicting the time left, meaning that the predictions were not distributed around the true value. This left the Kalman filter unable to correct the error since the implementation was of the most basic type, only able to handle gaussian noise. 

There are models designed for non-gaussian noise that could be implemented for future work.

\subsection{Gaussian Process Regression}
The Gaussian process regression approach only used 200 trajectories
for training, since it was very computationally expensive to evaluate
the model. When using all training trajectories, evaluation took too
long to be done before the project deadline. Using fewer trajectories
meant that the model considered fewer kinds of behaviours, which gave
it worse performance compared to a model training on all trajectories.

Apart from the fact that not all training data was used, the models performance was worse than expected. At times it was even as bad as the baseline model. Furthermore, it would be expected that the MAE decrease as larger parts of trajectories are observed by the model, since it can find likely trajectories easier with more data points, but this was not the case. This implies a bug in the implementation or, more likely, that the trajectory that the synchronisation GP was trained on was not well chosen. The synchronisation GP is by far the most critical and the most difficult piece of the model, and if the trajectories is not synchronised properly, the likelihood computed to weigh predictions would be nonsensical. 

\section{Future Work}
\label{sec:future-work}
This section describes areas of improvements worth investigating for the different models.

\subsection{Neural Network}
By having the schedule of the buses available, some new interesting approaches would be possible. At any given station the current delay could be fed into the neural network. Furthermore, a very simple baseline model could be created using the schedule. By simply using the offset of the last bus it should be possible to make acceptable predictions, as two subsequent buses often have similar delays due to traffic conditions.

Model M4 could possibly perform better if a longer sequence of data points were used. Due to hardware constraints, the model in this work uses sequences of 20 data points as input, more than that required additional memory. Doing this would either require additional hardware resources or some exploration of how to split the training into multiple sessions where the data is divided into smaller chunks.

A different approach to making predictions with neural networks could be to output distributions instead of single point estimates.

\subsection{Gaussian Process Regression}
The most central part of the model is the synchronisation of
trajectories, which is consequently the most important one to get
right. For this implementation, the trajectory to train the
synchronisation GP on was hand-picked by manually trying different
ones and observing plots. The trajectory used for training made a big
difference on how well the GP mapped coordinates into progress, and it
is very likely that the one picked is not the best since no methodical
approach was taken. Trying something methodical for doing this would
be a great improvement in model consistency, and something as simple as taking the
trajectory with mean arrival time would be something to start with. In
order to make the synchronisation GP better, support-data was generated
in each observed data point, but it could very well be done on a more
fine-grained interval, which may improve performance.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% lorem.tex ends here

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "demothesis"
%%% End: 
