{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "journey_cols = [\n",
    "    'timestamp', \n",
    "    'event', \n",
    "    'vehicle_id', \n",
    "    'line', \n",
    "    'longitude', \n",
    "    'latitude', \n",
    "    'direction', \n",
    "    'speed', \n",
    "    'station',\n",
    "    'journey_number',\n",
    "    'segment_number'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(columns=journey_cols).astype(dtype={\n",
    "    'timestamp': 'object', \n",
    "    'event': 'object',\n",
    "    'vehicle_id': 'int64',\n",
    "    'line': 'int64',\n",
    "    'longitude': 'float64', \n",
    "    'latitude': 'float64',\n",
    "    'direction': 'float64',\n",
    "    'speed': 'float64',\n",
    "    'station': 'object',\n",
    "    'journey_number': 'int64',\n",
    "    'segment_number': 'int64'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(glob.glob('/home/max/det-ar-lugnt/buslines/*')):\n",
    "    df = df.append(pickle.load(open(f, 'rb'))).astype(dtype={\n",
    "        'timestamp': 'object', \n",
    "        'event': 'object',\n",
    "        'vehicle_id': 'int64',\n",
    "        'line': 'int64',\n",
    "        'longitude': 'float64', \n",
    "        'latitude': 'float64',\n",
    "        'direction': 'float64',\n",
    "        'speed': 'float64',\n",
    "        'station': 'object',\n",
    "        'journey_number': 'int64',\n",
    "        'segment_number': 'int64'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No journey has more than 11 segments, which is good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['segment_number'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does some journeys have a fewer than 11 segments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('journey_number').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped[grouped['segment_number'] < 11]['journey_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 55 journeys, we can drop these.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bad data makes up ~1.50%\n"
     ]
    }
   ],
   "source": [
    "print('The bad data makes up ~{:.2f}%'.format(100 * 55 / df['journey_number'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets drop the rows where the journey has a fewer than 11 segments. This should retain around 98.5% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_journeys = grouped[grouped['segment_number'] < 11]['journey_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The good data that would be kept after dropping make up 98.76%\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print('The good data that would be kept after dropping make up {:.2f}%'.format(\n",
    "    100 * len(df[~df['journey_number'].isin(bad_journeys)].index) / len(df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df[~df['journey_number'].isin(bad_journeys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which unique stations do we have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Rydsv\\xe4gens \\xe4ndh\\xe5llpl.\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n"
     ]
    }
   ],
   "source": [
    "_ = [print(s) for s in df['station'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stations: 13\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique stations: {}'.format(len(df['station'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique stations look correct, i.e. we don't have any stations that *shouldn't* be part of the journey. \n",
    "\n",
    "Do we have the same number of unique stations for every journey?\n",
    "\n",
    "Note: we set `dropna=False` to also count the stations marked `None` due to missing station data some events, such as the *ObservedPositionEvent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('journey_number')['station'].nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 12])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems we have some journeys with only 12 unique stations, where it should be 13. Thankfully there are only a few of these journeys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "journey_number\n",
       "848     12\n",
       "860     12\n",
       "1051    12\n",
       "1197    12\n",
       "1217    12\n",
       "1957    12\n",
       "Name: station, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped[grouped.apply(lambda x: x != 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_journeys = [x for x in grouped[grouped.apply(lambda x: x != 13)].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check what happend in these journeys to make them have fewer unique stations.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journey: 848\n",
      "None\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n",
      "\n",
      "\n",
      "journey: 860\n",
      "None\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n",
      "\n",
      "\n",
      "journey: 1051\n",
      "None\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n",
      "\n",
      "\n",
      "journey: 1197\n",
      "None\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n",
      "\n",
      "\n",
      "journey: 1217\n",
      "None\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n",
      "\n",
      "\n",
      "journey: 1957\n",
      "None\n",
      "Bj\\xf6rnk\\xe4rrsskolan\n",
      "Als\\xe4ttersgatan\n",
      "Rydsv\\xe4gen 236\n",
      "Rydsv\\xe4gen 168\n",
      "M\\xe5rdtorpsgatan\n",
      "Ryd centrum\n",
      "Ostbrickan\n",
      "Solhaga\n",
      "Gamla Link\\xf6ping\n",
      "Vallaplan\n",
      "Parkgatan Link\\xf6ping\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for journey in bad_journeys:\n",
    "    print(f'journey: {journey}')\n",
    "    _= [print(s) for s in df[df['journey_number'] == journey]['station'].unique()]\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems they fired their *JourneyStartedEvent* at Björnkärrsskolan, the station after Rydsvägens Ändhållplats.\n",
    "\n",
    "Lets drop these journeys as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['journey_number'].isin(bad_journeys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are left with 3603 journeys, comprising 6935530 rows\n"
     ]
    }
   ],
   "source": [
    "print('We are left with {} journeys, comprising {} rows'.format(len(df['journey_number'].unique()), len(df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't think of anything else to check for right now, anyone have some ideas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bus203_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
